Virtual Assistant For  Desktop:-

It is a smart and customizable desktop assistant built using Python, Eel, HTML/CSS, and JavaScript. It helps you control your PC and mobile with simple voice or typed commands.And also include chat history between user and the Virtual Assistant .
 
 âœ¨ Features

- ğŸ™ï¸ **Voice & Text Control** â€“ Interact via speech or typing.
- ğŸ’» **Launch Desktop Applications** â€“ Open apps like Chrome, VS Code, or Notepad.
- ğŸŒ **Open Websites** â€“ Instantly visit your favorite URLs (YouTube, Google, etc.).
- ğŸ“ **Android Phone Call Control** â€“ Make and receive calls using ADB.
- ğŸ“² **WhatsApp Messaging & Calls** â€“ Send WhatsApp messages and initiate calls.
- ğŸ“” **Built-in Contact Book** â€“ Store and manage contact details.
- ğŸ™‹ **Personal Info Storage** â€“ Save and reuse your name, age, preferences, etc.
- ğŸ¤– **AI Chat Interaction** â€“ Smart chatbot fallback for unknown queries.
- ğŸµ **Play Media** â€“ Play songs or videos on YouTube
- ğŸ” **Face Recognition (Optional)** â€“ Secure login with face unlock.


---

## ğŸ› ï¸ Tech Stack

- **Python** (Backend logic & voice control)
- **Eel** (Python + Web frontend bridge)
- **HTML/CSS/JavaScript** (Frontend UI)
- **SpeechRecognition**, **Pyttsx3**, **pvporcupine** (Voice input/output & wake word)
- **ADB (Android Debug Bridge)** â€“ For controlling Android phones
- **SQLite** â€“ For storing contact and personal data
- **OpenCV** â€“ Optional face recognition feature
- **pywhatkit**, **pyautogui**, **webbrowser**, and more.

 ##Install Dependencies:-
Create a virtual environment:
python -m venv env
env\Scripts\activate  # On Windows

Required Libraries:-
eel
pyttsx3
speechrecognition
pyaudio
pywhatkit
pyautogui
opencv-python
opencv-contrib-python
requests
pillow
flask
pvporcupine

##Set Up ADB for Android Control:-
Install ADB 
Enable USB Debugging on your Android phone.
Connect via USB and run:
 command:- adb devices


## ğŸ“ Project Structure
VIRTUAL ASSISTANT/
â”‚
â”œâ”€â”€ engine/ # Core backend engine
â”‚ â”œâ”€â”€ auth/ # Face recognition module
â”‚ â”œâ”€â”€ chat_module.py # AI Chatbot logic
â”‚ â”œâ”€â”€ command.py # Command processing logic
â”‚ â”œâ”€â”€ config.py # Global settings
â”‚ â”œâ”€â”€ cookies.json # Chatbot cookies or tokens
â”‚ â”œâ”€â”€ Db.py # DB operations for contacts etc.
â”‚ â”œâ”€â”€ features.py # Feature implementations
â”‚ â””â”€â”€ helpers.py # Utility/helper functions
â”‚
â”œâ”€â”€ env.Deepa/ # Python virtual environment (optional)
â”‚
â”œâ”€â”€ Frontend/ # Web-based UI using Eel
â”‚ â”œâ”€â”€ controller.js
â”‚ â”œâ”€â”€ index.html
â”‚ â”œâ”€â”€ Main.js
â”‚ â”œâ”€â”€ script.js
â”‚ â””â”€â”€ style.css
â”‚
â”œâ”€â”€ photos/ # Photos used for face recognition
â”‚
â”œâ”€â”€ contacts.csv # Phonebook data (CSV)
â”œâ”€â”€ Deepa.db # SQLite database (contacts, history)
â”œâ”€â”€ device.bat # Batch file to launch assistant
â”œâ”€â”€ Main.py # Might be older or alternative entry point
â”œâ”€â”€ run.py # ğŸ”¥ Main script to start Jarvis
â”œâ”€â”€ test.py # Script for testing features
â”œâ”€â”€ whatsappTest.py # Standalone WhatsApp testing
â”œâ”€â”€ .gitignore # Ignore venv, pycache, etc.
â””â”€â”€ README.md # Project documentation (this file)



ğŸ“± Android Control Features:-
To use phone features:
Connect Android phone via USB
Enable Developer Options > USB Debugging
Run adb devices to confirm the device is detected

Supported Actions
ğŸ“ Make a phone call
âœ… Accept or disconnect incoming calls
ğŸ’¬ Send WhatsApp messages
ğŸ”— Mobile interaction from desktop

ğŸ§  How Virtual Assistant Works
Hotword Detection using Porcupine (e.g., â€œJarvisâ€)
Speech Recognition via Google Speech API
Command Matching using regex or keyword mapping
Action Execution using Python modules or browser calls
Fallback Chat to AI-based interaction when no match is found

 Run the Assistant:-
 command:-python run.py

 


